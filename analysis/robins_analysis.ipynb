{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Parsing Analysis\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "### Import I/O and confusion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import src.col_data as cd\n",
    "import src.confusion as cf\n",
    "import src.vocab as vcb\n",
    "%cd -\n",
    "import pickle\n",
    "from typing import List, Tuple, NamedTuple, Dict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import itertools as it\n",
    "from colorama import Fore, Back, Style\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colourful Labels\n",
    "\n",
    "These are used for some matrices, but maybe more importantly when printing sentences to get _flat_ graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fore = [Fore.BLACK, Fore.BLUE, Fore.CYAN, Fore.GREEN, Fore.LIGHTBLACK_EX, Fore.LIGHTBLUE_EX, Fore.LIGHTCYAN_EX, Fore.LIGHTGREEN_EX, Fore.LIGHTMAGENTA_EX, Fore.LIGHTRED_EX, Fore.LIGHTWHITE_EX, Fore.LIGHTYELLOW_EX, Fore.MAGENTA, Fore.RED, Fore.WHITE, Fore.YELLOW]\n",
    "back = [Back.BLACK, Back.BLUE, Back.CYAN, Back.GREEN, Back.LIGHTBLACK_EX, Back.LIGHTBLUE_EX, Back.LIGHTCYAN_EX, Back.LIGHTGREEN_EX, Back.LIGHTMAGENTA_EX, Back.LIGHTRED_EX, Back.LIGHTWHITE_EX, Back.LIGHTYELLOW_EX, Back.MAGENTA, Back.RED, Back.WHITE, Back.YELLOW]\n",
    "print(\" \".join([c + str(i) + Style.RESET_ALL for i, c in enumerate((fore))]))\n",
    "print(\" \".join([c + Fore.WHITE + str(i) + Style.RESET_ALL for i, c in enumerate((back))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_colors = {\"targ\": fore[15] + back[0], \"holder\": fore[3] + back[0]}\n",
    "\n",
    "d = {}\n",
    "d[\"exp-None\"] = back[2]\n",
    "d[\"exp-Positive\"] = back[1]\n",
    "d[\"exp-Negative\"] = back[13]\n",
    "d[\"exp-positive\"] = d[\"exp-Positive\"]\n",
    "d[\"exp-negative\"] = d[\"exp-Negative\"]\n",
    "d[\"exp-neutral\"] = d[\"exp-None\"]\n",
    "d[\"exp-conflict\"] = back[12]\n",
    "lbl_colors.update(d)\n",
    "\n",
    "d = {}\n",
    "d[\"IN:targ\"] = back[15] + fore[0]\n",
    "d[\"IN:holder\"] = back[3] + fore[0]\n",
    "d[\"IN:exp-None\"] = fore[2]\n",
    "d[\"IN:exp-Positive\"] = fore[1]\n",
    "d[\"IN:exp-Negative\"] = fore[13]\n",
    "d[\"IN:exp-positive\"] = d[\"IN:exp-Positive\"]\n",
    "d[\"IN:exp-negative\"] = d[\"IN:exp-Negative\"]\n",
    "d[\"IN:exp-neutral\"] = d[\"IN:exp-None\"]\n",
    "d[\"IN:exp-conflict\"] = fore[12]\n",
    "lbl_colors.update(d)\n",
    "print(\" \".join([c + l + Style.RESET_ALL for l,c in lbl_colors.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Main Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../data/sent_graphs/\"\n",
    "experiments = \"../experiments/\"\n",
    "runs = [str(i) for i in range(1,6)]\n",
    "languages = !ls $experiments\n",
    "x = languages[0]\n",
    "flavours = !ls $experiments/$x\n",
    "dev = \"dev.conllu\"\n",
    "test = \"test.conllu\"\n",
    "train = \"train.conllu\"\n",
    "dev_pred = dev + \".pred\"\n",
    "test_pred = test + \".pred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages, flavours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is everything where it should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in languages:\n",
    "    for f in flavours:\n",
    "        print(l,f, end=\"\\n\\t\")\n",
    "        !ls $data/$l/$f\n",
    "        for r in runs:\n",
    "            print(r, end =\"\")\n",
    "            !ls $experiments/$l/$f/$r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Vocabs per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in languages:\n",
    "    sentences = []\n",
    "    for f in flavours:\n",
    "        path = \"/\".join([data, l, f]) + \"/\"\n",
    "        for fn in [\"dev.conllu\", \"test.conllu\", \"train.conllu\"]:\n",
    "            sentences.extend(cd.read_col_data(path + fn))\n",
    "    forms, norms, lemmas, uposs, xposs, synrels, semrels, chars, scoperels = vcb.make_vocabs(sentences)\n",
    "    print([len(v.w2i) for v in [forms, norms, lemmas, uposs, xposs, synrels, semrels, chars, scoperels]])\n",
    "    vocabs = vcb.Vocabs(forms, norms, lemmas, uposs, xposs, synrels, semrels, chars, scoperels)\n",
    "    with open(f\"{l}_vocabs.pickle\", \"wb\") as fh:\n",
    "        pickle.dump(vocabs, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Data itself\n",
    "\n",
    "- how many arcs are there? per label? per POS pair? per dependencies?=\n",
    "- how long are they?\n",
    "- overlap between flavours\n",
    "\n",
    "### Results\n",
    "\n",
    "- how many arcs?\n",
    "- how long?\n",
    "- overlap between flavours\n",
    "- precision / recall / fscore per label / POS pair / dependencies / arc length\n",
    "- which schemes are best for which label?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(fn: str) -> vcb.Vocabs:\n",
    "    with open(fn, \"rb\") as fh:\n",
    "        v = pickle.load(fh)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colours for plotting\n",
    "colours = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little helper for plotting\n",
    "_1 = lambda x: 1 if x % 2 == 1 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Lengths\n",
    "\n",
    "Mostly uninteresting for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1/8\n",
    "for l in languages:\n",
    "    plots = {}\n",
    "    min_maxes = defaultdict(lambda : [float(\"inf\"), -float(\"inf\")])\n",
    "    for i, fl in enumerate(flavours):\n",
    "        xs = \"/\".join([data, l, fl])\n",
    "        v = load_vocab(l + \"_vocabs.pickle\")\n",
    "\n",
    "        sentences = []\n",
    "        for tdt in [train, dev, test]:\n",
    "            sentences.extend(cd.read_col_data(xs + \"/\" + tdt))\n",
    "\n",
    "        d = {}\n",
    "        for sentence in sentences:\n",
    "            m = sentence.make_matrix(\"scope\", label=True, w2i=v.scoperels.w2i)\n",
    "            for src, tgt in zip(*np.where(m != 0)):\n",
    "                if src == 0:\n",
    "                    lngth = 0\n",
    "                else:\n",
    "                    lngth = src - tgt\n",
    "                lbl = m[src, tgt]\n",
    "                if lbl not in d:\n",
    "                    d[lbl] = {}\n",
    "                if lngth not in d[lbl]:\n",
    "                    d[lbl][lngth] = 0\n",
    "                d[lbl][lngth] += 1\n",
    "        for lbl in d:\n",
    "            #print(v.scoperels.i2w[lbl])\n",
    "            xy = sorted(d[lbl].items(), key=lambda x: -x[1])\n",
    "            #print(xy)\n",
    "            xs, ys = zip(*xy)\n",
    "            min_maxes[lbl][0] = min([min(xs), min_maxes[lbl][0]])\n",
    "            min_maxes[lbl][1] = max([max(xs), min_maxes[lbl][1]])\n",
    "            if lbl not in plots:\n",
    "                plots[lbl] = []\n",
    "            plots[lbl].append((xs, ys, fl))\n",
    "    for lbl in plots:\n",
    "        fig, ax = plt.subplots(figsize=(19, 6))\n",
    "        ax.set_title(l + \" \" + v.scoperels.i2w[lbl])\n",
    "        min_max = min_maxes[lbl]\n",
    "        myrange = {i: j for j, i in enumerate(range(min_max[0], min_max[1] + 1))}\n",
    "        ax.set_xticks(np.arange(min_max[0], min_max[1]+1))\n",
    "        ax.set_xticklabels(np.arange(min_max[0], min_max[1]+1), rotation=45)\n",
    "        _xs = np.arange(min_max[0], min_max[1]+1)\n",
    "        #ax.set_xticklabels(max_ti.cks, rotation=45)\n",
    "        for i, (xs, ys, fl) in enumerate(plots[lbl]):\n",
    "            xs = np.array(xs)\n",
    "            #_xs = np.zeros(len(myrange))\n",
    "            _ys = np.zeros(len(myrange))\n",
    "            xs, ys = zip(*(sorted(zip(xs, ys), key=lambda x: x[1])))\n",
    "            for x,y in zip(xs, ys):\n",
    "                j = myrange[x]\n",
    "                _ys[j] = y\n",
    "            #plt.bar(_xs + (i * width/2 * _1(i)), _ys, width/2, color=colours[i], alpha=0.7, linewidth=0.8, edgecolor=colours[i], align=\"center\", label=fl)\n",
    "        ax.legend()\n",
    "        fig.tight_layout()\n",
    "        #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Runs for each Flavour\n",
    "\n",
    "### What is easy & what is difficult?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(\"/\".join(i) for i in it.product(runs, [test, dev]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arc(NamedTuple):\n",
    "    index: int\n",
    "    sen: cd.Sentence\n",
    "    w_i: cd.Token\n",
    "    w_j: cd.Token\n",
    "    i: int\n",
    "    j: int\n",
    "    lbl: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arcs(index, sentence: cd.Sentence, m: np.ndarray, i2w: Dict[float, str]) -> List[Arc]:\n",
    "    \"get all arcs in a given sentences\"\n",
    "    return [Arc(index, sentence, sentence[i-1], sentence[j-1], i, j, i2w[m[i,j]]) for i,j in zip(*np.nonzero(m))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlap\n",
    "# cell entries should match\n",
    "# should be nonzero for unlabelled\n",
    "# i,j == j,i for undirected\n",
    "def overlap(index: int,\n",
    "            sen1: cd.Sentence, m1: np.ndarray,\n",
    "            sen2: cd.Sentence, m2: np.ndarray,\n",
    "            i2w: Dict[float, str],\n",
    "            labelled: bool = True, direction: bool = True\n",
    "           ) -> List[Arc]:  # indices and label\n",
    "    results = []\n",
    "    assert m1.shape == m2.shape\n",
    "    #if not m1.shape == m2.shape:\n",
    "    #    print(m1.shape, m2.shape)\n",
    "    #    return results\n",
    "    d1, d2 = m1.shape\n",
    "    scnd_dim = lambda x: range(x, d2)\n",
    "    for i in range(d1):\n",
    "        if direction:\n",
    "            x = 0\n",
    "        else:\n",
    "            x = i\n",
    "        for j in scnd_dim(x):\n",
    "            if m1[i,j]:\n",
    "                a = m1[i,j]\n",
    "            elif m1[j,i] and not direction:\n",
    "                a = m1[j,i]\n",
    "            else:\n",
    "                continue\n",
    "            if m2[i,j]:\n",
    "                b = m2[i,j]\n",
    "            elif m2[j,i] and not direction:\n",
    "                b = m2[j,i]\n",
    "            else:\n",
    "                continue\n",
    "            if a == b:\n",
    "                results.append(Arc(index, sen1, sen1[i-1], sen1[j-1], i, j, i2w[a]))  # (i, j, a))\n",
    "            elif a and b and not labelled:\n",
    "                results.append(Arc(index, sen1, sen1[i-1], sen1[j-1], i, j, \"-Any-\"))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_arcs(arcs, mode: str = \"lbl\"):\n",
    "    \"prints the number of arcs of some type\"\n",
    "    d = {}\n",
    "    for arc in arcs:\n",
    "        if mode == \"lbl\":\n",
    "            x = arc.lbl\n",
    "        elif mode == \"upos\":\n",
    "            x = (arc.w_i.upos, arc.w_j.upos)\n",
    "        elif mode == \"lemma\":\n",
    "            x = (arc.w_i.lemma, arc.w_j.lemma)\n",
    "        elif mode == \"deprel\":\n",
    "            x = (arc.w_i.deprel, arc.w_j.deprel)\n",
    "        else:\n",
    "            raise ValueError(f\"no such {mode} implemented\")\n",
    "        if x not in d:\n",
    "            d[x] = 0\n",
    "        d[x] += 1\n",
    "    print(sorted(d.items(), key=lambda x: -x[1])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_overlapping(lang: str, cache):\n",
    "    \"outer function calling the others\"\n",
    "    v = load_vocab(lang + \"_vocabs.pickle\")\n",
    "    for i in range(1, len(flavours) + 1):\n",
    "        cnt = {}\n",
    "        for (_, combo), os in filter(lambda x: len(x[0][1]) == i, cache.items()):\n",
    "            for arc in os:\n",
    "                #if s == 0:\n",
    "                #    continue\n",
    "                if combo not in cnt:\n",
    "                    cnt[combo] = {}\n",
    "                if arc.lbl not in cnt[combo]:\n",
    "                    cnt[combo][arc.lbl] = []\n",
    "                cnt[combo][arc.lbl] += [arc]\n",
    "        print(i)\n",
    "        for combo in sorted(cnt, key=lambda x: len(x)):\n",
    "            print(combo)\n",
    "            for l in sorted(cnt[combo], key=lambda x: len(cnt[combo][x])):\n",
    "                print(l)\n",
    "                print_arcs(cnt[combo][l], \"lbl\")\n",
    "                print_arcs(cnt[combo][l], \"upos\")\n",
    "                print_arcs(cnt[combo][l], \"deprel\")\n",
    "                print_arcs(cnt[combo][l], \"lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapping(lang: str,\n",
    "                    datasplits: List[str],\n",
    "                    labelled: bool = True,\n",
    "                    direction: bool = True\n",
    "                    ):\n",
    "    \"get overlapping arcs for all flavour combinations: what do flavours have in common?\"\n",
    "    v = load_vocab(lang + \"_vocabs.pickle\")\n",
    "    sentences = {}\n",
    "    for fl in flavours:\n",
    "        xs = \"/\".join([data, lang, fl])\n",
    "        sentences[fl] = []\n",
    "        for ds in datasplits:\n",
    "            sentences[fl].extend([(sen, sen.make_matrix(\"scope\", label=True, w2i=v.scoperels.w2i))\n",
    "                                    for sen in cd.read_col_data(xs + \"/\" + ds)])\n",
    "            \n",
    "    cache = {}  # stores overlaps for sentences so that only those need to be compared    \n",
    "    i2w = v.scoperels.i2w\n",
    "    for combo_len in range(1, len(flavours) + 1):\n",
    "        for combo in it.combinations(flavours, combo_len):\n",
    "            for mi, smss in enumerate(zip(*(sentences[c] for c in combo))):\n",
    "                sss, mss = zip(*smss)\n",
    "                if len(combo) == 1:\n",
    "                    cache[(mi, combo)] = get_arcs(mi, sss[0], mss[0], i2w)\n",
    "                elif len(combo) == 2:\n",
    "                    cache[(mi, combo)] = overlap(mi, sss[0], mss[0], sss[1], mss[1], i2w, labelled, direction)\n",
    "                elif len(combo) > 2 and (mi, combo[:-1]) in cache:\n",
    "                    # compute overlap for the arcs in cache\n",
    "                    m = mss[-1]\n",
    "                    os = []\n",
    "                    for arc in cache[(mi, combo[:-1])]:\n",
    "                        if i2w[m[arc.i, arc.j]] == arc.lbl:\n",
    "                            os.append(arc)\n",
    "                    if os:\n",
    "                        cache[(mi, combo)] = os\n",
    "                else:\n",
    "                    # do nothing\n",
    "                    pass\n",
    "    return cache\n",
    "\n",
    "###\n",
    "\n",
    "for lang in languages:\n",
    "    print(lang)\n",
    "    eval_overlapping(lang, get_overlapping(lang, [dev]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix-based Measures\n",
    "\n",
    "The interesting ones here are **true positives, false positives, false negatives, false labels** and the derived **precision, recall, f-score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion(lang: str,\n",
    "                    pred_path: str,\n",
    "                    gold_path: str,\n",
    "                    datasplits: List[str],\n",
    "                    labelled: bool = True,\n",
    "                    direction: bool = True\n",
    "                    ):\n",
    "    \"prints evaluation measures and returns a dictionary with the eval counts and the conf-matrix\"\n",
    "    v = load_vocab(lang + \"_vocabs.pickle\")\n",
    "    pred_sentences = {}\n",
    "    gold_sentences = {}\n",
    "    results = {fl: [] for fl in flavours}\n",
    "    for fl in flavours:\n",
    "        xs = \"/\".join([pred_path, fl])\n",
    "        gxs = \"/\".join([gold_path, fl])\n",
    "        pred_sentences[fl] = []\n",
    "        gold_sentences[fl] = []\n",
    "        for ds in datasplits:\n",
    "            pred_sentences[fl].extend([(sen, sen.make_matrix(\"scope\", label=True, w2i=v.scoperels.w2i))\n",
    "                                    for sen in cd.read_col_data(xs + \"/1/\" + ds + \".pred\")])\n",
    "            gold_sentences[fl].extend([(sen, sen.make_matrix(\"scope\", label=True, w2i=v.scoperels.w2i))\n",
    "                                    for sen in cd.read_col_data(gxs + \"/\" + ds)])\n",
    "            \n",
    "    i2w = v.scoperels.i2w\n",
    "    for fl_i, fl in enumerate(flavours):\n",
    "        gss, gms = zip(*gold_sentences[fl])\n",
    "        pss, pms = zip(*pred_sentences[fl])\n",
    "        c = cf.confuse(gms, pms, i2w)\n",
    "        for i in range(4, len(c)):\n",
    "            results[fl].append(cf.fscore(i, c)[:-3])\n",
    "        results[fl] = (np.array(results[fl], dtype=int), c)\n",
    "\n",
    "    return results\n",
    "\n",
    "###\n",
    "# save the results and confusion matrices in separate dictionaries\n",
    "all_results = {}\n",
    "all_confusions = {}\n",
    "for lang in languages:\n",
    "    print(lang)\n",
    "    all_results[lang] = {}\n",
    "    all_confusions[lang] = {}\n",
    "    results = get_confusion(lang, \"/\".join([experiments, lang]), \"/\".join([data, lang]), [dev, test])\n",
    "    for flavour in results:\n",
    "        all_results[lang][flavour] = results[flavour][0]\n",
    "        all_confusions[lang][flavour] = results[flavour][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two types of flavours\n",
    "Two types of flavours to make some comparisons easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_flavours = [fl for fl in flavours if \"inside\" not in fl]\n",
    "inside_flavours = [fl for fl in flavours if \"inside\" in fl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare flavours pairwise for each language and take the difference between their evaluation counts.\n",
    "The matrices are colour-coded according to their labels they represent.\n",
    "This way we get an idea on how they directly compare to each other.\n",
    "Comparing `general_flavours` with `inside_flavours` can be confusing due to their different label sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    v = load_vocab(lang + \"_vocabs.pickle\")\n",
    "    labels = list(v.scoperels.w2i.keys())[4:]\n",
    "    print(lang)\n",
    "    for a,b in it.combinations(flavours, 2):\n",
    "        print(a, \" || \", b)\n",
    "        m = all_results[lang][a] - all_results[lang][b]\n",
    "        for i in range(len(m)):\n",
    "            if (m[i] == 0).all():\n",
    "                continue\n",
    "            print(\"\\t\" , lbl_colors[labels[i]] + str(m[i]) + Style.RESET_ALL)\n",
    "        print(\"\\t\", np.sum(m, 0), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_sentence(sentence, l2c):\n",
    "    \"print sentences and their graphs flatly encoded by colour to make simple comparisons easier\"\n",
    "    output = []\n",
    "    for token in sentence:\n",
    "        if token.scope:\n",
    "            if len(token.scope) > 1:\n",
    "                output.append(\"(\")\n",
    "                for _, l in token.scope:\n",
    "                    output.append(l2c[l] + token.form + Style.RESET_ALL)\n",
    "                    output.append(\"|\")\n",
    "                output.pop(-1)\n",
    "                output.append(\") \")\n",
    "            else:\n",
    "                output.append(l2c[token.scope[0][1]] + token.form + Style.RESET_ALL)\n",
    "                output.append(\" \")\n",
    "        else:\n",
    "            output.append(token.form)\n",
    "            output.append(\" \")\n",
    "    return \"\".join(output)\n",
    "\n",
    "# should proably be used to print into files, instead of blowing up the notebook\n",
    "with open(\"test.out\", \"w\") as f:\n",
    "    print(colored_sentence(sentence, lbl_colors), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More fun with evaluation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpfpfnfl(gold: List[cd.Sentence], pred: List[cd.Sentence], w2i: Dict[str, float], i2w: Dict[float, str]):\n",
    "    \"tpfpfnfl is a dictionary with the arcs of each category\"\n",
    "    results = {\"tp\": set(), \"fp\": set(), \"fn\": set(), \"fl\": set()}\n",
    "    for sid, (gs, ps) in enumerate(zip(gold, pred)):\n",
    "        gm = gs.make_matrix(\"scope\", label=True, w2i=w2i)\n",
    "        pm = ps.make_matrix(\"scope\", label=True, w2i=w2i)\n",
    "        d1, d2 = gm.shape\n",
    "        assert gm.shape == pm.shape\n",
    "        for i in range(d1):\n",
    "            for j in range(d2):\n",
    "                g = gm[i, j]\n",
    "                p = pm[i, j]\n",
    "                if g == p and g != 0:\n",
    "                    results[\"tp\"].add(Arc(sid, gs, gs[i-1], gs[j-1], i, j, i2w[gm[i, j]]))\n",
    "                elif g == 0 and p != 0:\n",
    "                    results[\"fp\"].add(Arc(sid, gs, gs[i-1], gs[j-1], i, j, i2w[pm[i, j]]))\n",
    "                elif p == 0 and g != 0:\n",
    "                    results[\"fn\"].add(Arc(sid, gs, gs[i-1], gs[j-1], i, j, i2w[gm[i, j]]))\n",
    "                elif g != 0 and p != 0 and g != p:\n",
    "                    results[\"fl\"].add(Arc(sid, gs, gs[i-1], gs[j-1], i, j, i2w[pm[i, j]]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get `tpfpfnfl` for all languages and flavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tpfpfnfl = {}\n",
    "for lang in languages:\n",
    "    tpfpfnfl[lang] = {}\n",
    "    v = load_vocab(lang + \"_vocabs.pickle\")\n",
    "    labels = list(v.scoperels.w2i.keys())[4:]\n",
    "    print(lang)\n",
    "    pred_path = \"/\".join([experiments, lang])\n",
    "    gold_path = \"/\".join([data, lang])\n",
    "    datasplits = [dev, test]\n",
    "    for fl in flavours:\n",
    "        print(\"\\t\", fl)\n",
    "        xs = \"/\".join([pred_path, fl])\n",
    "        gxs = \"/\".join([gold_path, fl])\n",
    "        pred = []\n",
    "        gold = []\n",
    "        for ds in datasplits:\n",
    "            pred.extend([sen for sen in cd.read_col_data(xs + \"/1/\" + ds + \".pred\")])\n",
    "            gold.extend([sen for sen in cd.read_col_data(gxs + \"/\" + ds)])\n",
    "        tpfpfnfl[lang][fl] = get_tpfpfnfl(gold, pred, v.scoperels.w2i, v.scoperels.i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(arc_set, combo, comboverlap):\n",
    "    \"counts for different types of arcs\"\n",
    "    # we lose the arc label since we want to compare across labels\n",
    "    results = {x: {} for x in \"total form upos xpos deprel\".split()}\n",
    "    for x in \"tp fp fn fl\".split():\n",
    "        results[\"total\"][x] = {}\n",
    "        results[\"form\"][x] = {}\n",
    "        results[\"upos\"][x] = {}\n",
    "        results[\"xpos\"][x] = {}\n",
    "        results[\"deprel\"][x] = {}\n",
    "        for a in combo:\n",
    "            results[\"total\"][x][a] = len(arc_set[a][x])\n",
    "            results[\"form\"][x][a] = Counter([(arc[1][1], arc[2][1]) for arc in arc_set[a][x]])\n",
    "            results[\"upos\"][x][a] = Counter([(arc[1][2], arc[2][2]) for arc in arc_set[a][x]])\n",
    "            results[\"xpos\"][x][a] = Counter([(arc[1][3], arc[2][3]) for arc in arc_set[a][x]])\n",
    "            results[\"deprel\"][x][a] = Counter([(arc[1][4], arc[2][4]) for arc in arc_set[a][x]])\n",
    "        results[\"total\"][x][combo] = len(arc_set[a][x])\n",
    "        results[\"form\"][x][combo] = Counter([(arc[1][1], arc[2][1]) for arc in comboverlap[combo][x]])\n",
    "        results[\"upos\"][x][combo] = Counter([(arc[1][2], arc[2][2]) for arc in comboverlap[combo][x]])\n",
    "        results[\"xpos\"][x][combo] = Counter([(arc[1][3], arc[2][3]) for arc in comboverlap[combo][x]])\n",
    "        results[\"deprel\"][x][combo] = Counter([(arc[1][4], arc[2][4]) for arc in comboverlap[combo][x]])\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_sets = {} # general arcs as tuples of sid, src, tgt\n",
    "# src/tgt consist of the index, form, upos, xpos, and deprel\n",
    "comboverlap = {} # how do combinations of flavours overlap?\n",
    "for lang in languages:\n",
    "    comboverlap[lang] = {}\n",
    "    arc_sets[lang] = {}\n",
    "    print(lang)\n",
    "    for flavour in flavours:\n",
    "        arc_sets[lang][flavour] = {x: set() for x in \"tp fp fn fl\".split()}\n",
    "        for x in tpfpfnfl[lang][flavour]:\n",
    "            arc_sets[lang][flavour][x] = set((arc.index, (arc.i, arc.w_i.form, arc.w_i.upos, arc.w_i.xpos, arc.w_i.deprel), (arc.j, arc.w_j.form, arc.w_j.upos, arc.w_j.xpos, arc.w_j.deprel)) for arc in tpfpfnfl[lang][flavour][x])\n",
    "    for combo_len in range(1, len(flavours) + 1):\n",
    "        for combo in it.combinations(flavours, combo_len):\n",
    "            comboverlap[lang][combo] = {x: set() for x in \"tp fp fn fl\".split()}\n",
    "            #print(combo)\n",
    "            for x in comboverlap[lang][combo]:\n",
    "                comboverlap[lang][combo][x] = arc_sets[lang][combo[0]][x].intersection(*(arc_sets[lang][ci][x] for ci in combo[1:]))\n",
    "                #print(f\"{x}: \" + \" \".join([f\"{len(arc_sets[lang][a][x])}\" for a in combo]) + f\" overlap: {len(comboverlap[lang][combo][x])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tpfpfnfl(title, tps, fps, fns, fls, lngth=10, dominator=\"total\"):\n",
    "    # dominator total looks at the total amount of mistakes\n",
    "    width = 1/4\n",
    "    tps_lbls = [x[0] for x in tps.most_common(lngth)]\n",
    "    fps_lbls = [x[0] for x in fps.most_common(lngth)]\n",
    "    fns_lbls = [x[0] for x in fns.most_common(lngth)]\n",
    "    fls_lbls = [x[0] for x in fls.most_common(lngth)]\n",
    "    totals = Counter() # only mistakes\n",
    "    for cnt in [fps, fns, fls]:\n",
    "        totals.update(cnt)\n",
    "    tot_lbls = [x[0] for x in totals.most_common(lngth)]\n",
    "    all_lbls = {\"tp\": tps_lbls, \"fp\": fps_lbls, \"fn\": fns_lbls, \"fl\": fls_lbls, \"total\": tot_lbls}\n",
    "    tpfpfnfls = {\"tp\": tps, \"fp\": fps, \"fn\": fns, \"fl\": fls}\n",
    "    lbls = all_lbls[dominator]\n",
    "    fig, ax = plt.subplots(figsize=(19, 6))\n",
    "    ax.set_title(title)\n",
    "    xs = np.arange(lngth)\n",
    "    ax.set_xticks(xs)\n",
    "    ax.set_xticklabels(lbls, rotation=45)\n",
    "    for i, x in enumerate(\"tp fp fn fl\".split()):\n",
    "        ys = [tpfpfnfls[x][y] for y in lbls]\n",
    "        plt.bar(xs + ((1+i) * width/2) - width, ys, width/2, color=colours[i], alpha=0.7, linewidth=0.8, edgecolor=colours[i], align=\"center\", label=x)\n",
    "    \n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot TpFpFnFl\n",
    "Plot for each language and flavour (combination) their (shared) evaluation counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    print(lang)\n",
    "    for combo_len in range(1, len(flavours) + 1):\n",
    "        for combo in it.combinations(flavours, combo_len):\n",
    "            print(combo)\n",
    "            results = get_counts(arc_sets[lang], combo, comboverlap[lang])\n",
    "            #for x in \"tp fp fn fl\".split():\n",
    "                #print(x)\n",
    "                #print(results[\"upos\"][x][combo].most_common(5))\n",
    "            category = \"deprel\"\n",
    "            plot_tpfpfnfl(lang + \" \" + str(combo), results[category][\"tp\"][combo],\n",
    "                          results[category][\"fp\"][combo],\n",
    "                          results[category][\"fn\"][combo], results[category][\"fl\"][combo],\n",
    "                          lngth=10, dominator=\"total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is flavour A better than flavour B?\n",
    "\n",
    "For each flavour-pair (A,B) look at the true positives in A and how many of those arc are in the various eval counts of B or do not have an equivalent arc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flavour_com_pair(d1, d2):\n",
    "    \"\"\"something is wrong here\"\"\"\n",
    "    diffs1 = {x: [arc for arc in d1[\"tp\"] if arc in d2[x]] for x in \"tp fp fn fl\".split()}\n",
    "    diffs2 = {x: [arc for arc in d2[\"tp\"] if arc in d1[x]] for x in \"tp fp fn fl\".split()}\n",
    "    diffs1[\"None\"] = [arc for arc in d1[\"tp\"] if arc not in [a for a in d2[x] for x in \"tp fp fn fl\".split()]]\n",
    "    diffs2[\"None\"] = [arc for arc in d2[\"tp\"] if arc not in [a for a in d1[x] for x in \"tp fp fn fl\".split()]]\n",
    "    print([(x, len(y)) for x,y in diffs1.items()])\n",
    "    print([(x, len(y)) for x,y in diffs2.items()])\n",
    "    return diffs1, diffs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flavour_compair(d1, d2):\n",
    "    diffs1 = {x: [] for x in \"tp fp fn fl None\".split()}\n",
    "    diffs2 = {x: [] for x in \"tp fp fn fl None\".split()}\n",
    "    for arc in d1[\"tp\"]:\n",
    "        if arc in d2[\"tp\"]:\n",
    "            diffs1[\"tp\"].append(arc)\n",
    "        elif arc in d2[\"fp\"]:\n",
    "            diffs1[\"fp\"].append(arc)\n",
    "        elif arc in d2[\"fn\"]:\n",
    "            diffs1[\"fn\"].append(arc)\n",
    "        elif arc in d2[\"fl\"]:\n",
    "            diffs1[\"fl\"].append(arc)\n",
    "        else:\n",
    "            diffs1[\"None\"].append(arc)\n",
    "    for arc in d2[\"tp\"]:\n",
    "        if arc in d1[\"tp\"]:\n",
    "            diffs2[\"tp\"].append(arc)\n",
    "        elif arc in d1[\"fp\"]:\n",
    "            diffs2[\"fp\"].append(arc)\n",
    "        elif arc in d1[\"fn\"]:\n",
    "            diffs2[\"fn\"].append(arc)\n",
    "        elif arc in d1[\"fl\"]:\n",
    "            diffs2[\"fl\"].append(arc)\n",
    "        else:\n",
    "            diffs2[\"None\"].append(arc)\n",
    "    print([(x, len(y)) for x,y in diffs1.items()])\n",
    "    print([(x, len(y)) for x,y in diffs2.items()])\n",
    "    return diffs1, diffs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# differences between pairs only maybe...\n",
    "pair_diffs = {}\n",
    "for lang in languages:\n",
    "    print(lang)\n",
    "    pair_diffs[lang] = {}\n",
    "    for fl1, fl2 in it.combinations(flavours, 2):\n",
    "        print(fl1, fl2)\n",
    "        d1 = arc_sets[lang][fl1]\n",
    "        d2 = arc_sets[lang][fl2]\n",
    "        flavour_compair(d1, d2)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between flavours by head comparison\n",
    "\n",
    "Comparing flavours is difficult, as they generally differ in their sources.\n",
    "Taking away sources and label-prefixes (`IN:`) throws away some information, but might allow for more comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatArc(NamedTuple):\n",
    "    index: int\n",
    "    sid: int\n",
    "    form: str\n",
    "    lemma: str\n",
    "    upos: str\n",
    "    xpos: str\n",
    "    deprel: str\n",
    "    j: int\n",
    "    lbl: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_cnts = \"tp fp fn fl\".split()\n",
    "flat_tpfpfnfl = {}\n",
    "for lang in languages:\n",
    "    print(lang)\n",
    "    flat_tpfpfnfl[lang] = {}\n",
    "    for fl in flavours:\n",
    "        print(fl)\n",
    "        flat_tpfpfnfl[lang][fl] = {}\n",
    "        for x in eval_cnts:\n",
    "            flat_tpfpfnfl[lang][fl][x] = []\n",
    "            for arc in tpfpfnfl[lang][fl][x]:\n",
    "                index = arc.index\n",
    "                sid = arc.sen.id\n",
    "                form = arc.w_j.form\n",
    "                lemma = arc.w_j.lemma\n",
    "                upos = arc.w_j.upos\n",
    "                xpos = arc.w_j.xpos\n",
    "                deprel = arc.w_j.deprel\n",
    "                j = arc.j\n",
    "                lbl = arc.lbl[3:] if arc.lbl.startswith(\"IN:\") else arc.lbl\n",
    "                flat_tpfpfnfl[lang][fl][x].append(FlatArc(index, sid, form, lemma, upos, xpos, deprel, j, lbl))\n",
    "        print([(k, len(v)) for k,v in tpfpfnfl[lang][fl].items()])\n",
    "        print([(k, len(v)) for k,v in flat_tpfpfnfl[lang][fl].items()])\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diffs(c1):\n",
    "    c1 = {k: v for k,v in c1.items() if v != 0}\n",
    "    fig, ax = plt.subplots(figsize=(19, 6))\n",
    "    #ax.set_title(title)\n",
    "    xs = np.arange(len(c1))\n",
    "    ax.set_xticks(xs)\n",
    "    ax.set_xticklabels(c1.keys(), rotation=45)\n",
    "    plt.plot(xs, c1.values(), \"-\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences between pairs only maybe...\n",
    "pair_diffs = {}\n",
    "for lang in languages:\n",
    "    print(lang)\n",
    "    pair_diffs[lang] = {}\n",
    "    for fl1, fl2 in it.combinations(flavours, 2):\n",
    "        print(fl1, fl2)\n",
    "        d1 = flat_tpfpfnfl[lang][fl1]\n",
    "        d2 = flat_tpfpfnfl[lang][fl2]\n",
    "        diffs1, diffs2 = flavour_compair(d1, d2)\n",
    "        ###\n",
    "        for x in \"fp fn\".split():\n",
    "            print(x)\n",
    "            c1 = Counter([arc.deprel for arc in diffs1[x]])\n",
    "            c2 = Counter([arc.deprel for arc in diffs2[x]])\n",
    "            c1.subtract(c2)\n",
    "            print(c1)\n",
    "            plot_diffs(c1)\n",
    "        ###\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flat_arcs(index, sen):\n",
    "    sid = sen.id\n",
    "    arcs = []\n",
    "    for j, token in enumerate(sen):\n",
    "        form = token.form\n",
    "        lemma = token.lemma\n",
    "        upos = token.upos\n",
    "        xpos = token.xpos\n",
    "        deprel = token.deprel\n",
    "        if token.scope:\n",
    "            for head, lbl in token.scope:   \n",
    "                lbl = lbl[3:] if lbl.startswith(\"IN:\") else lbl\n",
    "                arcs.append(FlatArc(index, sid, form, lemma, upos, xpos, deprel, j, lbl))\n",
    "    return arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"norec\"\n",
    "fl1 = \"head_final\"\n",
    "fl2 = \"head_final-inside_label-dep_edges\"\n",
    "d1 = flat_tpfpfnfl[lang][fl1]\n",
    "d2 = flat_tpfpfnfl[lang][fl2]\n",
    "print([(k, len(v)) for k,v in d1.items()])\n",
    "print([(k, len(v)) for k,v in d2.items()])\n",
    "diffs1, diffs2 = flavour_compair(d1, d2)\n",
    "print(sum([len(v) for v in diffs1.values()]), sum([len(v) for v in diffs2.values()]))\n",
    "#list(filter(lambda x: x.index == 616, diffs1[\"None\"])),\"xxx\", list(filter(lambda x: x.index == 616, diffs2[\"None\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in diffs1.keys():\n",
    "    print(x)\n",
    "    #print(\"\\t\", [(k,v) for k,v in Counter([arc.upos for arc in diffs1[x]]).most_common()])\n",
    "    #print(\"\\t\", [(k,v) for k,v in Counter([arc.xpos for arc in diffs1[x]]).most_common()])\n",
    "    #print([(k,v) for k,v in Counter([arc.lemma for arc in diffs1[x]]).most_common()])\n",
    "    #print(\"\\t\", [(k,v) for k,v in Counter([arc.deprel for arc in diffs1[x]]).most_common()])\n",
    "    #print(\"\\t\", [(k,v) for k,v in Counter([arc.deprel for arc in diffs2[x]]).most_common()])\n",
    "    c1 = Counter([arc.deprel for arc in diffs1[x]])\n",
    "    c2 = Counter([arc.deprel for arc in diffs2[x]])\n",
    "    c1.subtract(c2)\n",
    "    print(c1)\n",
    "    plot_diffs(c1)\n",
    "\n",
    "    c1 = Counter([arc.upos for arc in diffs1[x]])\n",
    "    c2 = Counter([arc.upos for arc in diffs2[x]])\n",
    "    c1.subtract(c2)\n",
    "    print(c1)\n",
    "    plot_diffs(c1)\n",
    "\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/\".join([data, lang, fl1]) + \"/\"\n",
    "with open(path + dev + \".flat\", \"w\") as fh:\n",
    "    for i, s in enumerate(cd.read_col_data(path + dev)):\n",
    "        #if s.id == \"000286-06-02\":\n",
    "            print(colored_sentence(s, lbl_colors), file=fh)\n",
    "            flats = get_flat_arcs(i, s)\n",
    "            print(len(flats), len(set(flats)))\n",
    "            ga = set(flats)\n",
    "\n",
    "path = \"/\".join([experiments, lang, fl1]) + \"/1/\"\n",
    "with open(path + dev + \".pred\" + \".flat\", \"w\") as fh:\n",
    "    for i, s in enumerate(cd.read_col_data(path + dev + \".pred\")):\n",
    "        #if s.id == \"000286-06-02\":\n",
    "            print(colored_sentence(s, lbl_colors), file=fh)\n",
    "            flats = get_flat_arcs(i, s)\n",
    "            print(len(flats), len(set(flats)))\n",
    "            pa = set(flats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/\".join([data, lang, fl2]) + \"/\"\n",
    "with open(path + dev + \".flat\", \"w\") as fh:\n",
    "    for i, s in enumerate(cd.read_col_data(path + dev)):\n",
    "        #if s.id == \"000286-06-02\":\n",
    "            print(colored_sentence(s, lbl_colors), file=fh)\n",
    "            flats = get_flat_arcs(i, s)\n",
    "            print(len(flats), len(set(flats)))\n",
    "            ga = set(flats)\n",
    "\n",
    "path = \"/\".join([experiments, lang, fl2]) + \"/1/\"\n",
    "with open(path + dev + \".pred\" + \".flat\", \"w\") as fh:\n",
    "    for i, s in enumerate(cd.read_col_data(path + dev + \".pred\")):\n",
    "        #if s.id == \"000286-06-02\":\n",
    "            print(colored_sentence(s, lbl_colors), file=fh)\n",
    "            flats = get_flat_arcs(i, s)\n",
    "            print(len(flats), len(set(flats)))\n",
    "            pa = set(flats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a by-hand gold-pred-flavour-by-flavour-comparison do the following:\n",
    "\n",
    "`paste data/sent_graphs/norec/head_final/dev.conllu.flat experiments/norec/head_final/1/dev.conllu.pred.flat data/sent_graphs/norec/head_final-inside_label-dep_edges/dev.conllu.flat experiments/norec/head_final-inside_label-dep_edges/1/dev.conllu.pred.flat -d \"\\n\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ga - gb), len(ga.intersection(pa)), len(ga - pa), len(pa - ga), len(gb.intersection(pb)), len(gb -pb), len(pb - gb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
